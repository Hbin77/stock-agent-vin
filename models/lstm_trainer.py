# models/lstm_trainer.py (Final Version)

import numpy as np
import pandas as pd
import os
import random
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from imblearn.over_sampling import SMOTE
from features.builder import create_lstm_dataset

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
seed_value = 42
os.environ['PYTHONHASHSEED'] = str(seed_value)
random.seed(seed_value)
np.random.seed(seed_value)
tf.random.set_seed(seed_value)

def train_and_evaluate(df):
    """SMOTEë¥¼ ì ìš©í•˜ì—¬ LSTM ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ìƒì„±, í•™ìŠµí•˜ê³  ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("\nğŸ§  LSTM ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ (SMOTE ì ìš©)...")
    
    features = [
        'close', 'RSI_14', 'MACD_12_26_9', 'BBP_20_2.0_2.0', 'OBV', 'OBV_MA10',
        'ATRr_14', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'fed_rate', 'usd_krw'
    ]
    target = 'target'
    
    features = [f for f in features if f in df.columns]

    X = df[features]
    y = df[target]
    
    time_steps = 60
    X_seq, y_seq = create_lstm_dataset(X, y, time_steps)
    
    if len(X_seq) == 0:
        print("âš ï¸ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (ë°ì´í„° ë¶€ì¡±).")
        return None

    split_index = int(len(X_seq) * 0.8)
    X_train, X_test = X_seq[:split_index], X_seq[split_index:]
    y_train, y_test = y_seq[:split_index], y_seq[split_index:]
    
    nsamples, nx, ny = X_train.shape
    X_train_2d = X_train.reshape((nsamples, nx * ny))
    
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_2d, y_train)
    X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], nx, ny))
    
    model = Sequential([
        LSTM(units=50, return_sequences=True, input_shape=(X_train_resampled.shape[1], X_train_resampled.shape[2])),
        Dropout(0.2),
        LSTM(units=50, return_sequences=False),
        Dropout(0.2),
        Dense(units=25),
        Dense(units=1, activation='sigmoid') 
    ])
    
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X_train_resampled, y_train_resampled, epochs=25, batch_size=32, validation_data=(X_test, y_test), verbose=0)
    
    print("âœ… LSTM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    # ë°±í…ŒìŠ¤íŒ…ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì „ì²´ ê¸°ê°„ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìƒì„±
    full_pred_proba = model.predict(X_seq)
    full_predictions = (full_pred_proba > 0.5).astype(int)
    
    # ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì‹œí€€ìŠ¤ ê¸¸ì´(60ì¼)ë§Œí¼ ì•ë¶€ë¶„ì´ ë¹„ê²Œ ë˜ë¯€ë¡œ, ì´ë¥¼ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ê¸¸ì´ì— ë§ê²Œ íŒ¨ë”© ì¶”ê°€
    padding = np.array([np.nan] * (len(df) - len(full_predictions)))
    
    # ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼(Series)ë§Œ ë°˜í™˜
    return pd.Series(np.concatenate([padding, full_predictions.flatten()]), index=df.index)