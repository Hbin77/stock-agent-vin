import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import requests
import psycopg2
from datetime import datetime, timedelta
from utils import db_handler
from config import NEWS_API_KEY

def fetch_and_store_news(ticker, company_name):
    """NewsAPIë¥¼ í†µí•´ íŠ¹ì • ì¢…ëª©ì˜ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì™€ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ“° '{ticker}'ì— ëŒ€í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • (ì˜ˆ: ìµœê·¼ 30ì¼)
    to_date = datetime.now()
    from_date = to_date - timedelta(days=30)
    
    url = (f'https://newsapi.org/v2/everything?'
           f'q="{company_name}"&' # ì •í™•ë„ë¥¼ ìœ„í•´ íšŒì‚¬ ì´ë¦„ì— ë”°ì˜´í‘œ ì¶”ê°€
           f'from={from_date.strftime("%Y-%m-%d")}&'
           f'to={to_date.strftime("%Y-%m-%d")}&'
           f'language=en&'
           f'sortBy=publishedAt&'
           f'apiKey={NEWS_API_KEY}')
           
    conn = None
    try:
        response = requests.get(url)
        response.raise_for_status()
        articles = response.json().get('articles', [])
        
        if not articles:
            print(f"'{ticker}'ì— ëŒ€í•œ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        conn = db_handler.get_db_connection()
        with conn.cursor() as cursor:
            new_news_count = 0
            for article in articles:
                # ì œëª©ì´ë‚˜ URLì´ ì—†ëŠ” ë‰´ìŠ¤ëŠ” ê±´ë„ˆëœ€
                if not article.get('title') or not article.get('url'):
                    continue

                sql = """
                INSERT INTO stock_news (ticker, published_at, title, url, source_name)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (url) DO NOTHING;
                """
                published_time = datetime.strptime(article['publishedAt'], '%Y-%m-%dT%H:%M:%SZ')
                
                data = (
                    ticker,
                    published_time,
                    article['title'],
                    article['url'],
                    article.get('source', {}).get('name')
                )
                cursor.execute(sql, data)
                # ì‹¤ì œë¡œ ìƒˆë¡œìš´ í–‰ì´ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if cursor.rowcount > 0:
                    new_news_count += 1

            conn.commit()
        print(f"âœ… '{ticker}' ë‰´ìŠ¤ {len(articles)}ê±´ ì²˜ë¦¬ ì™„ë£Œ (ì‹ ê·œ ì €ì¥: {new_news_count}ê±´).")

    except requests.exceptions.HTTPError as e:
        print(f"âŒ ë‰´ìŠ¤ API ìš”ì²­ ì‹¤íŒ¨: {e}. API í‚¤ ë˜ëŠ” ìš”ì²­ ì œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    conn = db_handler.get_db_connection()
    if conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT ticker, company_name FROM stock_master WHERE is_active = TRUE")
            tickers = cursor.fetchall()
        conn.close()

        for ticker, company_name in tickers:
            # ë‰´ìŠ¤ ê²€ìƒ‰ìš© íšŒì‚¬ ì´ë¦„ ì •ì œ
            clean_company_name = company_name.replace(' Inc.', '').replace(' Corporation', '').replace(',','').split(' ')[0]
            fetch_and_store_news(ticker, clean_company_name)