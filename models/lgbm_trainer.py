# models/lgbm_trainer.py (Final Version)

import lightgbm as lgb
import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

def train_and_evaluate(df):
    """LightGBM ëª¨ë¸ì„ ìƒì„±, í•™ìŠµí•˜ê³  ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("\nğŸŒ³ LightGBM ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ (SMOTE ì ìš©)...")
    
    features = [
        'close', 'RSI_14', 'MACD_12_26_9', 'BBP_20_2.0_2.0', 'OBV', 'OBV_MA10',
        'ATRr_14', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'fed_rate', 'usd_krw'
    ]
    target = 'target'
    
    features = [f for f in features if f in df.columns]
    
    X = df[features]
    y = df[target]

    if X.empty or y.empty:
        print("âš ï¸ LightGBM í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return None

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    
    lgb_clf = lgb.LGBMClassifier(random_state=42, verbosity=-1) # ë¡œê·¸ ì¶œë ¥ì„ ë”
    lgb_clf.fit(X_train_resampled, y_train_resampled)
    
    print("âœ… LightGBM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    full_predictions = lgb_clf.predict(X)
    
    return pd.Series(full_predictions, index=X.index)